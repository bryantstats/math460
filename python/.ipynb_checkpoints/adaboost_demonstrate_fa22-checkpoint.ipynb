{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost Demonstration\n",
    "\n",
    "This notebook demonstrates\n",
    "\n",
    "-  The decision boundary of Adaboost\n",
    "-  The effect of the learning rate \n",
    "-  The effect of the number of stumps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def AdaBoost_scratch(X,y, M, learning_rate, depth = 1):\n",
    "    #Initialization of utility variables\n",
    "    N = len(y)\n",
    "    estimator_list, y_predict_list, estimator_error_list, estimator_weight_list, sample_weight_list = [], [],[],[],[]\n",
    "\n",
    "    #Initialize the sample weights\n",
    "    sample_weight = np.ones(N) / N\n",
    "    sample_weight_list.append(sample_weight.copy())\n",
    "\n",
    "    #For m = 1 to M\n",
    "    for m in range(M):   \n",
    "\n",
    "        #Fit a classifier\n",
    "        estimator = DecisionTreeClassifier(max_depth = depth)\n",
    "        estimator.fit(X, y, sample_weight=sample_weight)\n",
    "        y_predict = estimator.predict(X)\n",
    "\n",
    "        #Misclassifications\n",
    "        incorrect = (y_predict != y)\n",
    "\n",
    "        #Estimator error\n",
    "        estimator_error = np.mean( np.average(incorrect, weights=sample_weight, axis=0))\n",
    "        \n",
    "        #Boost estimator weights\n",
    "        estimator_weight =  learning_rate * np.log((1. - estimator_error) / estimator_error)\n",
    "\n",
    "        #Boost sample weights\n",
    "        sample_weight *= np.exp(estimator_weight * incorrect * ((sample_weight > 0) | (estimator_weight < 0)))\n",
    "\n",
    "        #Save iteration values\n",
    "        estimator_list.append(estimator)\n",
    "        y_predict_list.append(y_predict.copy())\n",
    "        estimator_error_list.append(estimator_error.copy())\n",
    "        estimator_weight_list.append(estimator_weight.copy())\n",
    "        sample_weight_list.append(sample_weight.copy())\n",
    "        \n",
    "\n",
    "\n",
    "    #Convert to np array for convenience   \n",
    "    estimator_list = np.asarray(estimator_list)\n",
    "    y_predict_list = np.asarray(y_predict_list)\n",
    "    estimator_error_list = np.asarray(estimator_error_list)\n",
    "    estimator_weight_list = np.asarray(estimator_weight_list)\n",
    "    sample_weight_list = np.asarray(sample_weight_list)\n",
    "\n",
    "    #Predictions\n",
    "    preds = (np.array([np.sign((y_predict_list[:,point] * estimator_weight_list).sum()) for point in range(N)]))\n",
    "    \n",
    "    print('')\n",
    "    print('Accuracy = ', (preds == y).sum() / N) \n",
    "    print('')\n",
    "    \n",
    "    return estimator_list, estimator_weight_list, sample_weight_list\n",
    "\n",
    "def plot_AdaBoost_scratch_boundary(estimators,estimator_weights, X, y, N = 10,ax = None ):\n",
    "    \n",
    "    def AdaBoost_scratch_classify(x_temp, est,est_weights ):\n",
    "        '''Return classification prediction for a given point X and a previously fitted AdaBoost'''\n",
    "        temp_pred = np.asarray( [ (e.predict(x_temp)).T* w for e, w in zip(est,est_weights )]  ) / est_weights.sum()\n",
    "        return np.sign(temp_pred.sum(axis = 0))\n",
    "    \n",
    "    \n",
    "    '''Utility function to plot decision boundary and scatter plot of data'''\n",
    "    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    xx, yy = np.meshgrid( np.linspace(x_min, x_max, N), np.linspace(y_min, y_max, N))\n",
    "\n",
    "\n",
    "    zz = np.array( [AdaBoost_scratch_classify(np.array([xi,yi]).reshape(1,-1), estimators,estimator_weights ) for  xi, yi in zip(np.ravel(xx), np.ravel(yy)) ] )\n",
    "            \n",
    "    # reshape result and plot\n",
    "    Z = zz.reshape(xx.shape)\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.contourf(xx, yy, Z, 2, cmap='RdBu', alpha=.5)\n",
    "    ax.contour(xx, yy, Z,  2, cmap='RdBu')\n",
    "    ax.scatter(X[:,0],X[:,1], c = y, cmap = cm_bright)\n",
    "    ax.set_xlabel('$X_1$')\n",
    "    ax.set_ylabel('$X_2$')\n",
    "    \n",
    "def adaboost_steps(df, L=1):\n",
    "    df['Stump 1']=np.sign(x2-2.5).astype(int)\n",
    "    df['Weight 1'] = np.repeat(1/len(df), len(df))\n",
    "    e1 = df[df['Stump 1']*df['y']==-1]['Weight 1'].sum()\n",
    "\n",
    "    alpha1 = L*.5*np.log((1-e1)/e1)\n",
    "    alpha1\n",
    "    df['Weight 2'] = df['Weight 1']*np.exp(alpha1*(-df['y']*df['Stump 1']))\n",
    "    df['Weight 2'] = df['Weight 2']/sum(df['Weight 2'])\n",
    "    df\n",
    "\n",
    "    df['Stump 2']=-np.sign(x1-1.5).astype(int)\n",
    "    \n",
    "    e2 = df[df['Stump 2']*df['y']==-1]['Weight 2'].sum()\n",
    "\n",
    "    alpha2 = L*.5*np.log((1-e2)/e2)\n",
    "    df['Weight 3'] = df['Weight 2']*np.exp(alpha2*(-df['y']*df['Stump 2']))\n",
    "    df['Weight 3'] = df['Weight 3']/sum(df['Weight 3'])\n",
    "\n",
    "    df['Stump 3']=-np.sign(x1-4.5).astype(int)\n",
    "    e3 = df[df['Stump 3']*df['y']==-1]['Weight 3'].sum()\n",
    "\n",
    "    alpha3 = L*.5*np.log((1-e3)/e3)\n",
    "    \n",
    "    print('')\n",
    "    print('Voting Power of Stump 1:', np.round(alpha1, decimals=4))\n",
    "    print('Voting Power of Stump 2:', np.round(alpha2, decimals=4))\n",
    "    print('Voting Power of Stump 3:', np.round(alpha3, decimals=4))\n",
    "    print('')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='$X_1$', ylabel='$X_2$'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = np.array([1, 1, 2, 2, 3, 3, 3, 4, 5, 5])\n",
    "x2 = np.array([1, 3, 2, 4, 1, 2, 5, 4,   2, 5])\n",
    "y = np.array([ 1, 1,-1, 1,-1, -1, 1, 1,  -1,-1])\n",
    "\n",
    "\n",
    "X = np.vstack((x1,x2)).T\n",
    "df = pd.DataFrame({'x1':x1, 'x2':x2, 'y':y})\n",
    "\n",
    "ax = plt.gca()\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "scatter_weights = np.ones(len(y))\n",
    "ax.scatter(X[:,0],X[:,1], c = y, cmap = cm_bright, s = scatter_weights* 40)\n",
    "\n",
    "ax.set_xlabel('$X_1$')\n",
    "ax.set_ylabel('$X_2$')\n",
    "\n",
    "ax\n",
    "#plt.savefig('ada_scatter.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Number of Stumps\n",
    "\n",
    "### Too Small Number of Stumps:  \n",
    "- Bad Training Accruracy. \n",
    "- Fast Running Time\n",
    "\n",
    "### Too Large Number of Rounds:  \n",
    "- Good Training Accruracy (so may overfit). \n",
    "- Slow Running Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonou\\AppData\\Local\\Temp\\ipykernel_2184\\902192668.py:35: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  estimator_weight =  learning_rate * np.log((1. - estimator_error) / estimator_error)\n",
      "C:\\Users\\sonou\\AppData\\Local\\Temp\\ipykernel_2184\\902192668.py:38: RuntimeWarning: invalid value encountered in multiply\n",
      "  sample_weight *= np.exp(estimator_weight * incorrect * ((sample_weight > 0) | (estimator_weight < 0)))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mround\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      3\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.1\u001b[39m\n\u001b[1;32m----> 5\u001b[0m estimator_list, estimator_weight_list, sample_weight_list  \u001b[38;5;241m=\u001b[39m \u001b[43mAdaBoost_scratch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                                              \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m plot_AdaBoost_scratch_boundary(estimator_list, estimator_weight_list, X, y, N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m )\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mAdaBoost_scratch\u001b[1;34m(X, y, M, learning_rate, depth)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M):   \n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#Fit a classifier\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(max_depth \u001b[38;5;241m=\u001b[39m depth)\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     y_predict \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m#Misclassifications\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3_fa22\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3_fa22\\lib\\site-packages\\sklearn\\tree\\_classes.py:321\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    315\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_leaf_nodes \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m must be either None or larger than 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    316\u001b[0m             max_leaf_nodes\n\u001b[0;32m    317\u001b[0m         )\n\u001b[0;32m    318\u001b[0m     )\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[43m_check_sample_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDOUBLE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expanded_class_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3_fa22\\lib\\site-packages\\sklearn\\utils\\validation.py:1553\u001b[0m, in \u001b[0;36m_check_sample_weight\u001b[1;34m(sample_weight, X, dtype, copy)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1552\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1553\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample weights must be 1D array or scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3_fa22\\lib\\site-packages\\sklearn\\utils\\validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    797\u001b[0m         )\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3_fa22\\lib\\site-packages\\sklearn\\utils\\validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    108\u001b[0m         allow_nan\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m    112\u001b[0m     ):\n\u001b[0;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    117\u001b[0m             )\n\u001b[0;32m    118\u001b[0m         )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Change round and L to see the effect. \n",
    "round = 20\n",
    "L = .1\n",
    "\n",
    "estimator_list, estimator_weight_list, sample_weight_list  = AdaBoost_scratch(X,y, M=round, depth = 4, \n",
    "                                                                              learning_rate = L)\n",
    "\n",
    "plot_AdaBoost_scratch_boundary(estimator_list, estimator_weight_list, X, y, N = 50 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Learning Rate\n",
    "\n",
    "Learning Rate determines how fast the model learns.  It should be from 0 to 1.\n",
    "\n",
    "### Too Small Learning Rate means\n",
    "  \n",
    "- Require more rounds to learn the data. \n",
    "\n",
    "### Too Large Learning Rate means\n",
    "\n",
    "- May miss the convergent point for the model -> Low Accuracy! \n",
    "- If lucky, it may get to the convergent point faster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "x1 = np.array([1, 1, 2, 2, 3, 3, 3, 4, 5, 5])\n",
    "x2 = np.array([1, 3, 2, 4, 1, 2, 5, 4,   2, 5])\n",
    "y = np.array([ 1, 1,-1, 1,-1, -1, 1, 1,  -1,-1])\n",
    "\n",
    "X = np.vstack((x1,x2)).T\n",
    "df = pd.DataFrame({'x1':x1, 'x2':x2, 'y':y})\n",
    "\n",
    "ax = plt.gca()\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "scatter_weights = np.ones(len(y))\n",
    "ax.scatter(X[:,0],X[:,1], c = y, cmap = cm_bright, s = scatter_weights* 40)\n",
    "\n",
    "ax.set_xlabel('$X_1$')\n",
    "ax.set_ylabel('$X_2$')\n",
    "\n",
    "ax\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ac = pd.DataFrame([], columns=list(['Rounds','Learning Rate','Accuracy']))\n",
    "for rs in range(1, 50):\n",
    "    for lr in [.2,.8, 1]:\n",
    "        boost = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 1, max_leaf_nodes=2), \n",
    "                            algorithm = 'SAMME',n_estimators=rs, learning_rate=lr)\n",
    "        boost.fit(X,y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ac = pd.concat([ac, pd.DataFrame([[rs, lr, boost.score(X,y) ]], \n",
    "                                    columns=list(['Rounds','Learning Rate','Accuracy']))], ignore_index=True)\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "ax = sns.lineplot(x=\"Rounds\", y=\"Accuracy\", hue =ac['Learning Rate'].astype('category'),data=ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ax.get_figure()\n",
    "fig.savefig('learning_rate_vs_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "x1 = np.array([1, 1, 2, 2, 3, 3, 3, 4, 5, 5, 3])\n",
    "x2 = np.array([1, 3, 2, 4, 1, 2, 5, 4,   2, 5, 4])\n",
    "y = np.array([ 1, 1,-1, 1,-1, -1, 1, 1,  -1,-1, -1])\n",
    "\n",
    "X = np.vstack((x1,x2)).T\n",
    "df = pd.DataFrame({'x1':x1, 'x2':x2, 'y':y})\n",
    "\n",
    "ax = plt.gca()\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "scatter_weights = np.ones(len(y))\n",
    "ax.scatter(X[:,0],X[:,1], c = y, cmap = cm_bright, s = scatter_weights* 40)\n",
    "\n",
    "ax.set_xlabel('$X_1$')\n",
    "ax.set_ylabel('$X_2$')\n",
    "\n",
    "ax\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ac = pd.DataFrame([], columns=list(['Rounds','Learning Rate','Accuracy']))\n",
    "for rs in range(1, 50):\n",
    "    for lr in [.2, 2]:\n",
    "        boost = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 1, max_leaf_nodes=2), \n",
    "                            algorithm = 'SAMME',n_estimators=rs, learning_rate=lr)\n",
    "        boost.fit(X,y)\n",
    "        ac = ac.append(pd.DataFrame([[rs, lr, boost.score(X,y) ]], \n",
    "                                    columns=list(['Rounds','Learning Rate','Accuracy'])), ignore_index=True)\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "ax = sns.lineplot(x=\"Rounds\", y=\"Accuracy\", hue =ac['Learning Rate'].astype('category'),data=ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
