{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages Requirements**: You will need to install the `imageio`. Do the follow to install the package:\n",
    "\n",
    "- Open `Anaconda Prompt`\n",
    "- Type in `pip install imageio`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Label\n",
    "\n",
    "What do you want to recognize? Change the `lab` variable to get the desired label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = ['1','2','3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the reduced resolution for images\n",
    "\n",
    "This is the resolution of images used to train the model. If the dim = 75, it means each image will be convert to 32x32 pixel image. Since this is greyscale images, a 75x75 image means each row of the data will have 75*75 = 5625 columns. \n",
    "\n",
    "- Increase the resolution (set dim to a larger number) will increase trainingperformance (which could also lead to overfiting). \n",
    "- Increase the resolution also mean the computation time increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training in data\n",
    "\n",
    "The two below code cells import all the pictures of the digits and include it to the `Xtrain` and `ytrain`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the path to the folders that containing the images folder\n",
    "\n",
    "This is the folder that contains three images folders and the test image (`test.png`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pat = 'C:\\\\Users\\\\SON\\\\Dropbox\\\\git\\\\Math460\\\\python\\\\digits'\n",
    "#pat = 'C:\\\\Users\\\\snguyen4\\\\Dropbox\\\\git\\\\Math460\\\\python\\\\digits'\n",
    "import os\n",
    "pat=os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import first category image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pat + '\\\\1' \n",
    "names = [f for f in os.listdir(path)]\n",
    "\n",
    "im = imageio.imread(path+'\\\\'+names[0])\n",
    "im1 = resize(im, (dim, dim))\n",
    "im1 = im1[:,:,0]\n",
    "im1 = im1.reshape(-1).reshape(1, -1)\n",
    "Xtrain = im1\n",
    "\n",
    "for n in names[1:]:\n",
    "    im = imageio.imread(path+'\\\\'+n)\n",
    "    im1 = resize(im, (dim, dim))\n",
    "    im1 = im1[:,:,0]\n",
    "    im1 = im1.reshape(-1).reshape(1, -1)\n",
    "    Xtrain = np.append(Xtrain, im1,0)\n",
    "\n",
    "ytrain=np.repeat(lab[0],len(names))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import second category image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pat + '\\\\2' \n",
    "\n",
    "import os\n",
    "names = [f for f in os.listdir(path)]\n",
    "\n",
    "for n in names:\n",
    "    im = imageio.imread(path+'\\\\'+n)\n",
    "    im1 = resize(im, (dim, dim))\n",
    "    im1 = im1[:,:,0]\n",
    "    im1 = im1.reshape(-1).reshape(1, -1)\n",
    "    Xtrain = np.append(Xtrain, im1,0)\n",
    "\n",
    "ytrain=np.append(ytrain, np.repeat(lab[1],len(names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import third category image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pat + '\\\\3' \n",
    "import os\n",
    "names = [f for f in os.listdir(path)]\n",
    "\n",
    "for n in names:\n",
    "    im = imageio.imread(path+'\\\\'+n)\n",
    "    im1 = resize(im, (dim, dim))\n",
    "    im1 = im1[:,:,0]\n",
    "    im1 = im1.reshape(-1).reshape(1, -1)\n",
    "    Xtrain = np.append(Xtrain, im1,0)\n",
    "\n",
    "ytrain=np.append(ytrain, np.repeat(lab[2],len(names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Random Forest with the loaded data\n",
    "\n",
    "Notice `n_estimators` is the number of trees in the forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100) # this random forest has 100 trees. \n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Confusion Matrix:\n",
      "[[19  0  0]\n",
      " [ 0 27  0]\n",
      " [ 0  0 22]]\n",
      "===============\n",
      "Training Accuracy:\n",
      "1.0\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "ypred_train=model.predict(Xtrain)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(ypred_train, ytrain)\n",
    "print('===============')\n",
    "print('Confusion Matrix:')\n",
    "print(mat)\n",
    "print('===============')\n",
    "print('Training Accuracy:')\n",
    "print(mat.diagonal().sum()/mat.sum())\n",
    "print('===============')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on a new image\n",
    "\n",
    "Create a test image named `test.png` and save it to the same folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Input Image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 25 and input n_features is 225 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ca0560bf6045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'================================'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The model predicts:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \"\"\"\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    389\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 25 and input n_features is 225 "
     ]
    }
   ],
   "source": [
    "im = imageio.imread(pat +'\\\\test.png')\n",
    "print('Input Image')\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "from skimage.transform import resize\n",
    "im1 = resize(im, (dim, dim))\n",
    "print('Reduced Input Image')\n",
    "plt.imshow(im1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "im1 = im1[:,:,0]\n",
    "im1 = im1.reshape(-1).reshape(1, -1)\n",
    "\n",
    "\n",
    "print('')\n",
    "print('================================')\n",
    "print(\"The model predicts:\", model.predict(im1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: If the prediction is wrong, include the test image to the training data and retrain the model. Retest the model with a similar image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
